---
phase: 09-performance-optimization
plan: 03
type: execute
---

<objective>
Implement limited parallel card analysis with concurrency control and API rate monitoring.

Purpose: Achieve 2-3x speedup on card analysis phase with safe parallelization.
Output: Card analysis processing 2-3 uploads concurrently with rate limit protection.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-performance-optimization/DISCOVERY.md
@.planning/phases/09-performance-optimization/09-01-SUMMARY.md
@.planning/phases/09-performance-optimization/09-02-SUMMARY.md

# Source files:
@lib/run-engine/executor.ts
@lib/ai/provider.ts

# Key constraints from discovery:
- Maximum 2-3 concurrent AI requests (API rate limit safety)
- Each upload is independent (no data dependencies)
- Must monitor for 429 rate limit responses
- Use pLimit for concurrency control
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add p-limit dependency for concurrency control</name>
  <files>package.json</files>
  <action>
Install p-limit for concurrency control:

```bash
npm install p-limit
```

p-limit provides a simple way to limit concurrent async operations:
```typescript
import pLimit from 'p-limit';
const limit = pLimit(2); // Max 2 concurrent
await Promise.all(items.map(item => limit(() => processItem(item))));
```

This is a well-maintained, lightweight package with zero dependencies.
  </action>
  <verify>npm ls p-limit shows the package installed; grep "p-limit" package.json</verify>
  <done>p-limit installed for concurrency control</done>
</task>

<task type="auto">
  <name>Task 2: Implement parallel card analysis with concurrency limit</name>
  <files>lib/run-engine/executor.ts</files>
  <action>
Modify the card analysis executor to process uploads in parallel with a concurrency limit of 2-3.

Current pattern (sequential):
```typescript
for (const runUpload of run.runUploads) {
  // Process one at a time
  const result = await analyzer.analyzeDocument(...);
  await db.card.createMany(...);
}
```

New pattern (parallel with limit):
```typescript
import pLimit from 'p-limit';

// Limit concurrent AI calls to 2 (safe for API rate limits)
const CONCURRENCY_LIMIT = 2;
const limit = pLimit(CONCURRENCY_LIMIT);

// Process uploads in parallel with concurrency control
await Promise.all(
  run.runUploads.map(runUpload =>
    limit(async () => {
      // Update status to LOADING
      await db.runUpload.update({
        where: { id: runUpload.id },
        data: { status: RunUploadStatus.LOADING },
      });

      // Analyze document (AI call)
      const result = await analyzer.analyzeDocument(...);

      // Batch create cards
      if (result.cards.length > 0) {
        await db.card.createMany({ data: result.cards.map(...) });
      }

      // Update status to COMPLETED
      await db.runUpload.update({
        where: { id: runUpload.id },
        data: {
          status: RunUploadStatus.COMPLETED,
          completedAt: new Date(),
        },
      });

      // Increment counter (atomic increment is safe)
      await db.run.update({
        where: { id: runId },
        data: {
          completedItems: { increment: 1 },
          totalCards: { increment: result.cards.length },
        },
      });
    })
  )
);
```

Key safeguards:
1. CONCURRENCY_LIMIT = 2 keeps us well under API rate limits
2. Each upload updates its own status (no shared state)
3. Counter increments use Prisma's atomic increment (safe for concurrency)
4. Wrap in try/catch to handle individual upload failures gracefully
  </action>
  <verify>npx tsc --noEmit passes; grep -n "pLimit" lib/run-engine/executor.ts shows concurrency control</verify>
  <done>Card analysis processes uploads in parallel with concurrency limit</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Parallel card analysis with 2-concurrent upload processing</what-built>
  <how-to-verify>
    1. Deploy to Vercel or run locally: npm run dev
    2. Create a new project with 4-6 document uploads
    3. Start card analysis
    4. Observe: Analysis should complete ~2x faster than before
    5. Verify in logs/console: Should see 2 uploads processing simultaneously
    6. Verify all cards created correctly (no duplicates, no missing)
    7. Check Run status completes as SUCCEEDED

    Watch for:
    - Any 429 rate limit errors from Claude API (should not occur with limit=2)
    - Correct progress updates (should show parallel progress)
    - All uploads marked COMPLETED
    - totalCards count matches actual cards created
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 9, or describe any issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds without errors
- [ ] p-limit package installed
- [ ] executor.ts uses concurrency-limited parallel processing
- [ ] Human verification passed
- [ ] No 429 rate limit errors observed
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Card analysis ~2x faster with parallel processing
- No race conditions or data corruption
- No API rate limit errors
- Phase 9 complete
</success_criteria>

<output>
After completion, create `.planning/phases/09-performance-optimization/09-03-SUMMARY.md`
</output>
